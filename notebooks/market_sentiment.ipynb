{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21448bdd",
   "metadata": {},
   "source": [
    "# Market Sentiment with Alpha Vantage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5778f5cd",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adf696f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/severinspagnola/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, requests, pandas as pd, numpy as np\n",
    "from datetime import timedelta, timezone\n",
    "import datetime as dt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AV_BASE = \"https://www.alphavantage.co/query\"\n",
    "FINBERT = \"yiyanghkust/finbert-tone\"  # finance-tuned sentiment\n",
    "EMBED   = \"sentence-transformers/all-MiniLM-L6-v2\"  # swap later if you have a finance ST model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a88d71",
   "metadata": {},
   "source": [
    "### News Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_news(tickers, days_back=7, limit=50):\n",
    "    from datetime import datetime, timedelta, timezone\n",
    "\n",
    "    # Alpha Vantage expects this time format: YYYYMMDDTHHMM\n",
    "    start = (datetime.now(timezone.utc) - timedelta(days=days_back)).strftime(\"%Y%m%dT%H%M\")\n",
    "\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"tickers\": \",\".join([t.upper() for t in tickers[:20]]),\n",
    "        # ✅ FIX: AV recently renamed these keys in some regions\n",
    "        \"time_from\": start,                # ok\n",
    "        \"sort\": \"LATEST\",\n",
    "        \"limit\": limit,                    # can stay as int\n",
    "        \"apikey\": os.getenv(\"ALPHAVANTAGE_API_KEY\"),\n",
    "    }\n",
    "\n",
    "    # ❗ FIX: remove any None or empty values before calling\n",
    "    params = {k: v for k, v in params.items() if v not in [None, \"\"]}\n",
    "\n",
    "    r = requests.get(AV_BASE, params=params, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(f\"HTTP {r.status_code}: {r.text}\")\n",
    "\n",
    "    data = r.json()\n",
    "\n",
    "    # Alpha Vantage sometimes returns a nested “Information” if tickers are invalid\n",
    "    if \"Information\" in data:\n",
    "        print(\"⚠️ Alpha Vantage said:\", data[\"Information\"])\n",
    "        print(\"Try fewer tickers or only one symbol (e.g., AAPL).\")\n",
    "        raise RuntimeError(\"Invalid tickers or unsupported combination.\")\n",
    "\n",
    "    if \"Note\" in data:\n",
    "        print(\"⚠️ Rate limit hit:\", data[\"Note\"])\n",
    "        time.sleep(15)\n",
    "        return fetch_news(tickers, days_back, limit)\n",
    "\n",
    "    if \"feed\" not in data:\n",
    "        raise RuntimeError(f\"Unexpected response: {data}\")\n",
    "\n",
    "    # Normal parsing\n",
    "    rows = []\n",
    "    for item in data[\"feed\"]:\n",
    "        for ts in item.get(\"ticker_sentiment\", []):\n",
    "            rows.append({\n",
    "                \"dt\": pd.to_datetime(item.get(\"time_published\"), format=\"%Y%m%dT%H%M%S\", utc=True, errors=\"coerce\"),\n",
    "                \"ticker\": ts.get(\"ticker\"),\n",
    "                \"title\": item.get(\"title\") or \"\",\n",
    "                \"summary\": item.get(\"summary\") or \"\",\n",
    "                \"source\": item.get(\"source\"),\n",
    "                \"url\": item.get(\"url\"),\n",
    "                \"av_relevance\": float(ts.get(\"relevance_score\") or 0),\n",
    "                \"av_sentiment\": float(ts.get(\"ticker_sentiment_score\") or 0),\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(\"⚠️ No articles found — try a shorter date range or single ticker.\")\n",
    "        return df\n",
    "\n",
    "    df[\"text\"] = (df[\"title\"].fillna(\"\").str.strip() + \". \" + df[\"summary\"].fillna(\"\").str.strip()).str.strip()\n",
    "    df = df[df[\"text\"].str.len() > 0].drop_duplicates(subset=[\"url\", \"ticker\"])\n",
    "    return df.sort_values(\"dt\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def fetch_multi_tickers(ticker_list, days_back=7, limit=50, sleep_s=12):\n",
    "    \"\"\"Fetch news for multiple tickers sequentially (respects Alpha Vantage limits).\"\"\"\n",
    "    all_frames = []\n",
    "    for t in ticker_list:\n",
    "        try:\n",
    "            print(f\"→ Fetching {t} …\")\n",
    "            df = fetch_news([t], days_back=days_back, limit=limit)\n",
    "            if not df.empty:\n",
    "                all_frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error fetching {t}: {e}\")\n",
    "        time.sleep(sleep_s)  # respect ~5 requests/min free-tier rule\n",
    "    if all_frames:\n",
    "        return pd.concat(all_frames, ignore_index=True)\n",
    "    return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3defa",
   "metadata": {},
   "source": [
    "### finBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e92ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    tok = AutoTokenizer.from_pretrained(FINBERT)\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(FINBERT)\n",
    "    pipe = TextClassificationPipeline(model=mdl, tokenizer=tok, return_all_scores=True, truncation=True)\n",
    "    emb  = SentenceTransformer(EMBED)\n",
    "    return pipe, emb\n",
    "\n",
    "def finbert_and_embed(df, pipe, emb, max_len=256, batch=32):\n",
    "    texts = df[\"text\"].tolist()\n",
    "    scores = []\n",
    "    for i in range(0, len(texts), batch):\n",
    "        out = pipe(texts[i:i+batch], max_length=max_len)\n",
    "        for row in out:\n",
    "            d = {dct[\"label\"].lower(): dct[\"score\"] for dct in row}\n",
    "            scores.append([d.get(\"positive\",0.0), d.get(\"neutral\",0.0), d.get(\"negative\",0.0)])\n",
    "    S = np.array(scores) if scores else np.zeros((0,3))\n",
    "    df[\"finbert_pos\"] = S[:,0]\n",
    "    df[\"finbert_neu\"] = S[:,1]\n",
    "    df[\"finbert_neg\"] = S[:,2]\n",
    "    vecs = emb.encode(texts, batch_size=batch, convert_to_numpy=True, normalize_embeddings=True) if len(texts) else np.zeros((0,384))\n",
    "    # store embeddings as JSON strings for now; for true modeling, use Parquet/npy\n",
    "    df[\"embed\"] = [v.tolist() for v in vecs]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd492c",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news…\n",
      "Got 219 rows\n",
      "Scoring with FinBERT + embeddings…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/severinspagnola/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "assert os.getenv(\"ALPHAVANTAGE_API_KEY\"), \"Set ALPHAVANTAGE_API_KEY in your .env\"\n",
    "\n",
    "tickers = sys.argv[1:] or [\"AAPL\",\"MSFT\",\"NVDA\"]\n",
    "print(\"Fetching news…\")\n",
    "#df_news = fetch_news(tickers, days_back=7, limit=50)\n",
    "df_news = fetch_news([\"AAPL\"], days_back=7, limit=50)\n",
    "print(f\"Got {len(df_news)} rows\")\n",
    "\n",
    "if df_news.empty:\n",
    "    sys.exit(0)\n",
    "\n",
    "print(\"Scoring with FinBERT + embeddings…\")\n",
    "pipe, emb = load_models()\n",
    "df = finbert_and_embed(df_news, pipe, emb)\n",
    "\n",
    "out_csv = \"news_finbert_sample.csv\"\n",
    "df[[\"dt\",\"ticker\",\"source\",\"url\",\"av_relevance\",\"av_sentiment\",\"finbert_pos\",\"finbert_neu\",\"finbert_neg\",\"title\",\"summary\",\"embed\"]].to_csv(out_csv, index=False)\n",
    "print(f\"Saved {out_csv} — ready to join with prices for labels.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
