{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21448bdd",
   "metadata": {},
   "source": [
    "# Market Sentiment with Alpha Vantage\n",
    "\n",
    "So far in this code I've built the basic pipeline to just pull news articles from Alpha Vantage and then pass them into finBERT before putting all of that data into a CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5778f5cd",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Set up all the environment variables and install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adf696f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, requests, pandas as pd, numpy as np\n",
    "from datetime import timedelta, timezone\n",
    "import datetime as dt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AV_BASE = \"https://www.alphavantage.co/query\"\n",
    "FINBERT = \"yiyanghkust/finbert-tone\"  # finance-tuned sentiment\n",
    "EMBED   = \"sentence-transformers/all-MiniLM-L6-v2\"  # swap later if you have a finance ST model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a88d71",
   "metadata": {},
   "source": [
    "### News Setup\n",
    "\n",
    "Setup the functions to pull all the news/media data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5adf6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_news(tickers, days_back=7, limit=50):\n",
    "    from datetime import datetime, timedelta, timezone\n",
    "\n",
    "    # Alpha Vantage expects this time format: YYYYMMDDTHHMM\n",
    "    start = (datetime.now(timezone.utc) - timedelta(days=days_back)).strftime(\"%Y%m%dT%H%M\")\n",
    "\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"tickers\": \",\".join([t.upper() for t in tickers[:20]]),\n",
    "        \"time_from\": start,                # ok\n",
    "        \"sort\": \"LATEST\",\n",
    "        \"limit\": limit,                    # can stay as int\n",
    "        \"apikey\": os.getenv(\"ALPHAVANTAGE_API_KEY\"),\n",
    "    }\n",
    "    \n",
    "    # Remove empty params\n",
    "    params = {k: v for k, v in params.items() if v not in [None, \"\"]}\n",
    "\n",
    "    r = requests.get(AV_BASE, params=params, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(f\"HTTP {r.status_code}: {r.text}\")\n",
    "\n",
    "    data = r.json()\n",
    "\n",
    "    # Alpha Vantage sometimes returns a nested “Information” if tickers are invalid\n",
    "    if \"Information\" in data:\n",
    "        print(\"Error; Alpha Vantage said:\", data[\"Information\"])\n",
    "        raise RuntimeError(\"Invalid tickers or unsupported combination.\")\n",
    "\n",
    "    if \"Note\" in data:\n",
    "        print(\"Rate limit hit:\", data[\"Note\"])\n",
    "        time.sleep(15)\n",
    "        return fetch_news(tickers, days_back, limit)\n",
    "\n",
    "    if \"feed\" not in data:\n",
    "        raise RuntimeError(f\"Unexpected response: {data}\")\n",
    "\n",
    "    # Normal parsing\n",
    "    rows = []\n",
    "    for item in data[\"feed\"]:\n",
    "        for ts in item.get(\"ticker_sentiment\", []):\n",
    "            rows.append({\n",
    "                \"dt\": pd.to_datetime(item.get(\"time_published\"), format=\"%Y%m%dT%H%M%S\", utc=True, errors=\"coerce\"),\n",
    "                \"ticker\": ts.get(\"ticker\"),\n",
    "                \"title\": item.get(\"title\") or \"\",\n",
    "                \"summary\": item.get(\"summary\") or \"\",\n",
    "                \"source\": item.get(\"source\"),\n",
    "                \"url\": item.get(\"url\"),\n",
    "                \"av_relevance\": float(ts.get(\"relevance_score\") or 0),\n",
    "                \"av_sentiment\": float(ts.get(\"ticker_sentiment_score\") or 0),\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(\"No articles found.\") # Maybe try a shorter date range?\n",
    "        return df\n",
    "\n",
    "    df[\"text\"] = (df[\"title\"].fillna(\"\").str.strip() + \". \" + df[\"summary\"].fillna(\"\").str.strip()).str.strip()\n",
    "    df = df[df[\"text\"].str.len() > 0].drop_duplicates(subset=[\"url\", \"ticker\"])\n",
    "    return df.sort_values(\"dt\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Here we define a function to fetch news for multiple tickers\n",
    "# I think the free tier of Alpha Vantage has limits disallowing us to pull from multiple tickers at once, \n",
    "# or it's just not supported\n",
    "def fetch_multi_tickers(ticker_list, days_back=7, limit=50, sleep_s=12):\n",
    "    all_frames = []\n",
    "    for t in ticker_list:\n",
    "        try:\n",
    "            print(f\"> Fetching {t} …\")\n",
    "            df = fetch_news([t], days_back=days_back, limit=limit)\n",
    "            if not df.empty:\n",
    "                all_frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error fetching {t}: {e}\")\n",
    "        time.sleep(sleep_s)  # ~5 requests/min free-tier rule?\n",
    "    if all_frames:\n",
    "        return pd.concat(all_frames, ignore_index=True)\n",
    "    return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3defa",
   "metadata": {},
   "source": [
    "### finBERT\n",
    "\n",
    "Now here's where we get into the actual ML pipeline, finBERT takes all of the news data and converts all the words into positive, neutral, and negative scores, that tell us how good or bad the given news article is.\n",
    "\n",
    "So far we just store all this data in a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e92ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    # Create a Hugging Face tokenizer (this basically allows the finbert model to read text)\n",
    "    tok = AutoTokenizer.from_pretrained(FINBERT)\n",
    "    # Load the finbert model\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(FINBERT)\n",
    "    # Wrap model & tokenizer in a sentiment pipeline; return scores for all labels + truncate long texts\n",
    "    pipe = TextClassificationPipeline(model=mdl, tokenizer=tok, return_all_scores=True, truncation=True)\n",
    "    # Load the model for sentence embeddings\n",
    "    emb  = SentenceTransformer(EMBED)\n",
    "    # Return both the sentiment pipeline and the embedding model\n",
    "    return pipe, emb\n",
    "\n",
    "def finbert_and_embed(df, pipe, emb, max_len=256, batch=32):\n",
    "    texts = df[\"text\"].tolist()\n",
    "    scores = []\n",
    "    # Iterate through texts in batches to speed up inference \n",
    "    # Doing smaller chunks sequentially is faster than doing one big batch all at once\n",
    "    for i in range(0, len(texts), batch):\n",
    "        # Run FINBERT on the current batch; limit tokenized length to max_len\n",
    "        out = pipe(texts[i:i+batch], max_length=max_len)\n",
    "        for row in out:\n",
    "            d = {dct[\"label\"].lower(): dct[\"score\"] for dct in row}\n",
    "            scores.append([d.get(\"positive\",0.0), d.get(\"neutral\",0.0), d.get(\"negative\",0.0)])\n",
    "    S = np.array(scores) if scores else np.zeros((0,3))\n",
    "    df[\"finbert_pos\"] = S[:,0]\n",
    "    df[\"finbert_neu\"] = S[:,1]\n",
    "    df[\"finbert_neg\"] = S[:,2]\n",
    "    vecs = emb.encode(texts, batch_size=batch, convert_to_numpy=True, normalize_embeddings=True) if len(texts) else np.zeros((0,384))\n",
    "    # store embeddings as JSON strings for now; for true modeling, use parquet/numpy\n",
    "    df[\"embed\"] = [v.tolist() for v in vecs]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd492c",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a604ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news…\n",
      "Got 221 rows\n",
      "Scoring with FinBERT + embeddings…\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     sys.exit(\u001b[32m0\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mScoring with FinBERT + embeddings…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m pipe, emb = \u001b[43mload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m df = finbert_and_embed(df_news, pipe, emb)\n\u001b[32m     16\u001b[39m out_csv = \u001b[33m\"\u001b[39m\u001b[33mnews_finbert_sample.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_models\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m tok = AutoTokenizer.from_pretrained(FINBERT)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the finbert model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m mdl = \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFINBERT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Wrap model & tokenizer in a sentiment pipeline; return scores for all labels + truncate long texts\u001b[39;00m\n\u001b[32m      7\u001b[39m pipe = TextClassificationPipeline(model=mdl, tokenizer=tok, return_all_scores=\u001b[38;5;28;01mTrue\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/transformers/modeling_utils.py:5048\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5038\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5039\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5041\u001b[39m     (\n\u001b[32m   5042\u001b[39m         model,\n\u001b[32m   5043\u001b[39m         missing_keys,\n\u001b[32m   5044\u001b[39m         unexpected_keys,\n\u001b[32m   5045\u001b[39m         mismatched_keys,\n\u001b[32m   5046\u001b[39m         offload_index,\n\u001b[32m   5047\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5048\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5054\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5056\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5059\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5062\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5063\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5064\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5065\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/transformers/modeling_utils.py:5316\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5313\u001b[39m     original_checkpoint_keys = \u001b[38;5;28mlist\u001b[39m(state_dict.keys())\n\u001b[32m   5314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5315\u001b[39m     original_checkpoint_keys = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m5316\u001b[39m         \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m.keys()\n\u001b[32m   5317\u001b[39m     )\n\u001b[32m   5319\u001b[39m \u001b[38;5;66;03m# Check if we are in a special state, i.e. loading from a state dict coming from a different architecture\u001b[39;00m\n\u001b[32m   5320\u001b[39m prefix = model.base_model_prefix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/transformers/modeling_utils.py:526\u001b[39m, in \u001b[36mload_state_dict\u001b[39m\u001b[34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_file, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m map_location != \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_zipfile(checkpoint_file):\n\u001b[32m    525\u001b[39m         extra_args = {\u001b[33m\"\u001b[39m\u001b[33mmmap\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/torch/serialization.py:1521\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1528\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/torch/serialization.py:2122\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2120\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2121\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2122\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2123\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2125\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/torch/_weights_only_unpickler.py:412\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    410\u001b[39m         error_msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m which belongs to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__self__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(error_msg)\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m torch._tensor_classes \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msparse\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m func.\u001b[34m__module__\u001b[39m:\n\u001b[32m    414\u001b[39m     _sparse_tensors_to_validate.append(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/torch/_utils.py:225\u001b[39m, in \u001b[36m_rebuild_tensor_v2\u001b[39m\u001b[34m(storage, storage_offset, size, stride, requires_grad, backward_hooks, metadata)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_rebuild_tensor_v2\u001b[39m(\n\u001b[32m    217\u001b[39m     storage,\n\u001b[32m    218\u001b[39m     storage_offset,\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m     metadata=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    224\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     tensor = \u001b[43m_rebuild_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     tensor.requires_grad = requires_grad\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/project-fa25-QVP/venv/lib/python3.13/site-packages/torch/_utils.py:188\u001b[39m, in \u001b[36m_rebuild_tensor\u001b[39m\u001b[34m(storage, storage_offset, size, stride)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_rebuild_tensor\u001b[39m(storage, storage_offset, size, stride):\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# first construct a tensor with the correct dtype/device\u001b[39;00m\n\u001b[32m    187\u001b[39m     t = torch.empty((\u001b[32m0\u001b[39m,), dtype=storage.dtype, device=storage._untyped_storage.device)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_untyped_storage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "assert os.getenv(\"ALPHAVANTAGE_API_KEY\"), \"Set ALPHAVANTAGE_API_KEY in your .env\"\n",
    "\n",
    "tickers = sys.argv[1:] or [\"AAPL\",\"MSFT\",\"NVDA\"]\n",
    "print(\"Fetching news…\")\n",
    "df_news = fetch_news([\"AAPL\"], days_back=7, limit=50)\n",
    "print(f\"Got {len(df_news)} rows\")\n",
    "\n",
    "if df_news.empty:\n",
    "    sys.exit(0)\n",
    "\n",
    "print(\"Scoring with FinBERT + embeddings…\")\n",
    "pipe, emb = load_models()\n",
    "df = finbert_and_embed(df_news, pipe, emb)\n",
    "\n",
    "out_csv = \"news_finbert_sample.csv\"\n",
    "df[[\"dt\",\"ticker\",\"source\",\"url\",\"av_relevance\",\"av_sentiment\",\"finbert_pos\",\"finbert_neu\",\"finbert_neg\",\"title\",\"summary\",\"embed\"]].to_csv(out_csv, index=False)\n",
    "print(f\"Saved {out_csv} — ready to join with prices for labels.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
